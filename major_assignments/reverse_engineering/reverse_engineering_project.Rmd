---
title: "Reverse Engineering Project Final Notebook"
author: "Sasha Allen, Nick Elliot, Hannah Marszalek, Bode Ramsay"
date: "11/02/2023"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

In this notebook, we are reverse engineering the story, ["As police struggle to solve homicides, Baltimore residents see an 'open season for killing'"](https://www.washingtonpost.com/investigations/as-police-struggle-to-solve-homicides-baltimore-residents-see-an-open-season-for-killing/2018/12/26/7ee561e4-fb24-11e8-8c9a-860ce2a8148f_story.html) from *The Washington Post*. We have chosen five sentences from the story that we felt revealed a reliance on data analysis and have recreated that analysis with our own code. Those sentences and our analysis can be found below.

## Load libraries

Loading required libraries for this analysis.

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(lubridate)
library(janitor)
library(ggplot2)
library(ggthemes)
```

## Load and Cleaning Data

This homicide data comes from [The Washington Post's Github page](https://github.com/washingtonpost/data-homicides), and it includes data from 50 police departments that were chosen based on their city's size and violent crime reported to the FBI in 2012. The file they provided includes information regarding when the homicide was reported, where it took place, the status of the case, and some basic demographic information about the victim. While most departments provided information from a full decade (2007-2017), New York City only provided two years, which made some of our analysis a bit more challenging.

```{r}
#Loading homicide data from The Washington Post
homicide_data <- read_csv("data/homicide-data.csv")

#Cleaning data by making a formatted date column and a separate year column
homicide_data <- homicide_data %>%
  mutate(reported_date = ymd(reported_date), 
         year = year(reported_date))
```

## Sentences to Engineer

### Sentence 1

-   **Sentence text:** "As Baltimore has seen a stunning surge of violence, with nearly a killing each day for the past three years in a city of 600,000, homicide arrests have plummeted."
-   **Analysis summary:** By filtering for only the killings that happened in the latter half of the provided decade in Baltimore and then grouping by year, we were able to see that the total number per year was fairly close to 365 for 2015, 2016, and 2017, thus confirming their claim that there was nearly a killing each day. We also added a column showing the average number of killings per day, all of which were above 0.5, to further prove this. By including some of the years before this three-day period, we were also able to demonstrate how there has been a surge in the numbers, going from 0.59 per day in 2012 to 0.93 per day in 2017.

```{r}
#Filtering for Baltimore and the specific years and creating a new column with daily average
past_years <- homicide_data %>%
  filter(city == "Baltimore") %>%
  filter(year == "2012" | year == "2013" | year == "2014" | year == "2015" | year == "2016" | year == "2017") %>%
  group_by(year) %>%
  summarise(
    total_killings = n(),
    avg_per_day = total_killings/365
  )
  
#Displaying the resulting table
past_years
```

```{r}
#Creating a bar chart to display Baltimore homicides per year
past_years %>%
  ggplot() +
  geom_bar(aes(x=year, weight=total_killings)) +
  scale_x_continuous(breaks=c(2012, 2013, 2014, 2015, 2016, 2017)) +
  labs(
    title="Total Homicides Per Year in Baltimore",
    x = "year",
    y = "number of homicides",
    caption = "source: The Washington Post"
    ) +
  theme_clean()
```

### Sentence 2

-   **Sentence text:** "Of 50 of the nation's largest cities, Baltimore is one of 34 where police now make homicide arrests less often than in 2014, according to a Washington Post analysis."
-   **Analysis summary:** To do our analysis, we found the number of homicide arrests per city in 2014 and then in 2017 since this is the most recent year for which we have data, then joined these data frames to compare the numbers. Using percent change, we could determine that the cities with a negative percent change were the ones where the number of homicide arrests decreased between these two years. Unfortunately we were not able to confirm their finding, for the list we created only had 24 cities and Baltimore was not on the list, and it does seem as though certain cities do not have complete data for every year.

```{r}
#Finding number of homicide arrests per city in 2014
arrests_2014 <- homicide_data %>%
  filter(year == "2014" & disposition == "Closed by arrest") %>%
  group_by(city) %>%
  summarize(arrests_2014 = n())

#Finding number of homicide arrests per city in 2017
arrests_2017 <- homicide_data %>%
  filter(year == "2017" & disposition == "Closed by arrest") %>%
  group_by(city) %>%
  summarize(arrests_2017 = n())

#Joining the two dataframes to compare the 2014 and 2017 counts and calculating the percent change
homicide_arrests <- arrests_2014 %>%
  left_join(arrests_2017) %>%
  mutate(pct_change = (arrests_2017 - arrests_2014)/arrests_2014) %>%
  filter(pct_change < 0)

#Displaying the resulting table
homicide_arrests
```

### Sentence 3

-   **Sentence text:** "Baltimore is also one of 30 cities that have seen an increase in homicides in recent years, with the greatest raw number increase in killings of any city other than Chicago, which has four times the population."
-   **Analysis summary:** While it is not completely clear from the sentence in the article what the Washington Post counted as "recent years," we decided to compare the number of killings per city in 2012 and 2017. Upon calculating the difference for each city, we found that the top three cities as far as increases in homicides are Chicago, Las Vegas, and Baltimore. This is slightly different from the results described in the story since they said Baltimore was second to Chicago and our list only had 23 cities instead of 30, which means their definition of "recent years" may have been different from ours.

```{r}
#Finding homicide count for 2012
homicide_count_2012 <- homicide_data %>%
  filter(year == "2012") %>%
  group_by(city) %>%
  summarize(homicide_count_2012 = n())

#Finding homicide count for 2017
homicide_count_2017 <- homicide_data %>%
  filter(year == "2017") %>%
  group_by(city) %>%
  summarize(homicide_count_2017 = n())

#Joining the two and creating a column to calculate the raw number increase
homicide_data_combined <- homicide_count_2017 %>%
  left_join(homicide_count_2012) %>%
  filter(city != "New York") %>%
  mutate(raw_number_increase = homicide_count_2017 - homicide_count_2012) %>%
  filter(raw_number_increase > 0) %>%
  arrange(desc(raw_number_increase))

# Displaying the resulting table
homicide_data_combined
```

### Sentence 4

-   **Sentence text:** "For most of the decade before 2015, Baltimore's annual homicide arrest rate hovered at about 40 percent. Since 2015, the arrest rate hasn't topped 30 percent in any year."
-   **Analysis summary:** After calculating the arrest rate for each year in their dataset, we were able to confirm that this sentence is in fact correct. From 2007 to 2014 the arrest rate stayed within the range of 39-42%, yet after 2014, the highest it reached was 27.35% in 2017.

```{r}
#Filtering for only Baltimore homicides that resulted in arrest and grouping by year
baltimore_arrests_by_year <- homicide_data %>%
  filter(city == "Baltimore") %>%
  filter(disposition == "Closed by arrest") %>%
  group_by(year) %>%
  summarize(arrests = n())

#Filtering for all Baltimore homicides and grouping by year
baltimore_homicides_by_year <- homicide_data %>%
  filter(city == "Baltimore") %>%
  group_by(year) %>%
  summarize(homicides = n())

#Joining the two dataframes and creating a column to calculate the arrest rate per year
baltimore_arrest_rate <- baltimore_arrests_by_year %>%
  left_join(baltimore_homicides_by_year, by = "year") %>%
  mutate(arrest_rate = (arrests/homicides)*100)

#Displaying the resulting table
baltimore_arrest_rate
```

### Sentence 5

-   **Sentence text:** "Of the 1,002 homicides between 2015 and the beginning of this year, just 252 --- one out of every four --- resulted in an arrest."
-   **Analysis summary**: As shown in our analysis, the first dataset containing the number of cases during this time has 1,002 cases shown by the number of rows, and the second dataset showing the number of cases closed by arrest has 252 rows. Each of these numbers are exactly correct compared to the numbers used in the story. Also, regarding their claim that one out of every four homicides resulted in an arrest, we were able to confirm this by calculating the percent using the number of rows in each of these dataframes and multiplying it by 100. The resulting number was 25.15, which therefore proves their point since 25% is the same as 1/4.

```{r}
#Filtering for only homicides in Baltimore from 2015 to 2017
recent_baltimore_homicides <- homicide_data %>%
  filter(city == "Baltimore", year == "2015" | year == "2016" | year == "2017")

#Filtering for only homicides that we closed by arrest
total_arrest_count <- recent_baltimore_homicides %>%
  filter(disposition == "Closed by arrest")

#Calculating the percent of Baltimore homicides from these years that resulted in arrest
nrow(total_arrest_count)/nrow(recent_baltimore_homicides)*100
```

-30-
